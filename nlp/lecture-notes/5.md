```markdown
# Lecture Notes: Sequence Classification and Sequence Labeling

**Course:** Natural Language Processing
**Lecturer:** Mark Carman
**Textbook Reference:** "Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition" by Daniel Jurafsky and James H. Martin.

---

## Lecture Contents (Slide 2)

*   Importance of Word Order
*   Sequence Classification vs Labelling
*   Traditional Sequence Labelling Models: HMMs and CRFs
*   Recurrent Neural Networks
*   NLP Applications:
    *   POS tagging
    *   Named Entity Recognition
    *   Entity Linking
    *   Relation Extraction
    *   Parse Trees
    *   Co-reference Resolution
    *   Ontologies

---

## I. Word Order (Slides 3-4)

### A. Importance of Word Order (Slide 4)

*   Word order is crucial for interpreting the meaning of text and for classifying it.
*   **Example (Intended Meaning):**
    *   "There’s a **white rat** in the house …"
    *   "There’s a rat in the **White House** …" (Different meaning due to "White House" as a named entity).
*   **Negation:** A particularly important example where word order dictates sentiment.
    *   "I am **not happy** about going to school tomorrow." (Negative sentiment)
    *   "I am happy about **not going** to school tomorrow." (Positive sentiment)
*   N-grams can capture some word order information, but often cannot be made long enough to capture all necessary context.

---

## II. Sequence Classification vs Sequence Labelling (Slide 5)

*   **Sequence Classification Task:**
    *   **Input:** Ordered sequence of tokens: `(w₁, w₂, ..., wₙ)`
    *   **Output:** Single prediction for the entire sequence: `y`
    *   *Example:* "the dog chewed my slippers" -> `y = unhappy` (Sentiment classification)
*   **Sequence Labelling Task:**
    *   **Input:** Ordered sequence of tokens: `(w₁, w₂, ..., wₙ)`
    *   **Output:** Sequence of predictions/labels, one for each token: `(y₁, y₂, ..., yₙ)`
    *   *Example:* "the dog chewed my slippers" -> "my" / `y₄ = possessive determiner` (POS tagging)
*   **Note:**
    *   Prediction for `yᵢ` can depend on the entire sequence `(w₁, ..., wₙ)`.
    *   Predicted values `yᵢ` often depend on each other and other values of `yⱼ` (especially neighboring ones).

---

## III. How do Sequence Labellers Work? (Slide 6)

*   **Traditional Methods:**
    *   **Hidden Markov Models (HMMs):**
        *   Analogous to Naïve Bayes applied to sequences.
        *   Consist of:
            *   Unobserved (hidden) states (e.g., POS tags).
            *   Observed words.
            *   Transition probabilities: `P(state₂ | state₁)` (linking hidden states).
            *   Emission probabilities: `P(word | state)` (linking words to hidden states).
        *   Parameter estimation: Count frequencies from hand-labeled data (or use Expectation-Maximization - EM - if hidden states are unknown).
    *   **Conditional Random Fields (CRFs):**
        *   Analogous to Logistic Regression applied to sequences.
        *   Replace transition and emission probabilities with **undirected potentials** (feature functions) over cliques, e.g., `φ(t₁, t₂)` (transition potential) and `φ(t₁, w₁)` (emission/state-observation potential).
        *   Often achieve better performance than HMMs by relaxing the generative independence assumptions. Parameter estimation remains similar (e.g., iterative scaling).
*   **Recent Methods:**
    *   Make use of **Recurrent Neural Networks (RNNs)** to further improve performance.

---

## IV. Recurrent Neural Networks (RNNs) (Slides 7-11)

### A. Aggregating Embeddings (Slide 8)

*   Word embeddings represent words in a semantic space.
*   To represent a whole document, we could sum embeddings (like one-hot encodings for bag-of-words).
*   **Problem:** Documents with different word order but the same words (e.g., "white rat in the house" vs. "rat in the white house") would end up with the same representation, despite having different meanings.

### B. Recurrent Neural Networks (RNNs) - Overview (Slide 9)

*   RNNs allow us to aggregate information over a document **while not ignoring word order**.
*   Provide a general way to **accumulate information** by:
    *   Combining the embedding of the current word.
    *   With context (hidden state) from the previous words.
*   **RNNs are models which:**
    *   Take 2 vectors as input: `<current input (word embedding), previous state (hidden state)>`.
    *   Produce 2 vectors as output: `<current output (optional), updated state (hidden state)>`.
*   Can process **arbitrarily long input contexts** (e.g., encode a sequence of text to a single embedding/final hidden state).

### C. Long Short-Term Memory (LSTM) (Slide 10)

*   A clever implementation of an RNN that is able to learn **contexts** and **long-range dependencies**.
*   Achieved by using a **gating mechanism**:
    *   Information passes through by default.
    *   **Input gate:** Controls when new information is added to the cell state.
    *   **Forget gate:** Controls when information is deleted (forgotten) from the cell state.
    *   **Output gate:** Controls what is output from the cell state to the hidden state/prediction.
*   LSTM learns when & what information to **remember, forget, and output** at each timestep.

### D. Aside: LSTMs and Handling Context (Slide 11)

*   LSTMs can be **stacked** on top of each other.
*   They have an uncanny ability to handle **nested contexts**.
*   **Useful for natural language:**
    *   Completing sentences with correct pronoun agreement: "My mother was talking to her friend Jim. Jim said that his favourite game was confusing his students. Replying, she said that he should find a better hobby." (Handles gender changes).
    *   Handling negation and complex sentence structures: "I get along well with her brother. He’s always ___. I can not get along well with her brother. He’s always ___. I can not help but get along well with her brother. He’s always ___." (LSTMs can switch between sentence and negation contexts).

---

## V. NLP Applications of Sequence Classifiers and Labellers (Slides 12-36)

*   Many applications, including: part-of-speech tagging, named entity extraction, entity linkage, relation extraction, dependency parsing, co-reference resolution.

### A. Part-of-Speech (POS) Tagging (Slides 14-19)

*   **Parts of Speech Classes (Slide 15):**
    *   Word classes have existed since antiquity (e.g., Dionysius Thrax, 1st century BCE: nouns, verbs, etc.).
    *   Modern grammar divides words into:
        *   **Open class ("content") words:** Nouns, Verbs, Adjectives, Adverbs, Interjections.
        *   **Closed class ("function") words:** Determiners, Auxiliary verbs, Prepositions, Particles, Conjunctions, Pronouns, Numerals.
*   **What is POS Tagging? (Slide 16):**
    *   The task of assigning a part-of-speech label to each token in a sequence.
    *   E.g., `PRON` (pronoun), `VERB`, `DET` (determiner), `NOUN`.
    *   **Why label POS?**
        *   Useful for developing features (e.g., authorship attribution).
        *   Reduces ambiguity in bag-of-words (e.g., "book_VERB" vs. "book_NOUN").
        *   Initial step for other NLP tasks (syntactic parsing, text-to-speech).
        *   Linguistic analysis (creation of new words, meaning shift).
*   **Parts of Speech Tagging - Example (Slide 17):**
    *   Map sequence of words `x₁,...,xₙ` to sequence of POS tags `y₁,...,yₙ`.
    *   Example: "Janet (NOUN) will (AUX) back (VERB) the (DET) bill (NOUN)."
    *   A comprehensive tagset includes tags like ADJ, NOUN, VERB, PROPN, ADP, AUX, CCONJ, DET, NUM, PART, PRON, SCONJ, PUNCT, SYM, X.
*   **How difficult is POS tagging? (Slide 18):**
    *   ~85% of vocabulary terms in English are unambiguous (e.g., "Janet" is always PROPN, "hesitantly" is always ADV).
    *   However, ambiguous vocabulary terms are very common (~60% of tokens are ambiguous).
    *   Example: "back" can be ADJ, NOUN, VERB, PART (particle, as in "buy back"), ADV.
    *   Accuracy of POS tagging is ~97% (similar to human accuracy).
    *   Baseline (label each word with its most frequent tag) is already ~92%.
*   **Features used for POS tagging (Slide 19):**
    *   **Prior probabilities of word/tag:** e.g., "will" is usually an AUX.
    *   **Identity of neighboring words:** e.g., "the" often precedes a NOUN, not a VERB.
    *   **Morphology and wordshape:**
        *   Prefixes: "un-" (e.g., "unable") often indicates ADJ.
        *   Suffixes: "-ly" (e.g., "importantly") often indicates ADV.
        *   Capitalization: "Janet" (capitalized) often indicates PROPN.

### B. Named Entity Recognition (NER) (Slides 20-24)

*   **What is Entity Recognition? (Slide 21):**
    *   Task of identifying mentions of named entities in text.
    *   Can be treated as a sequence labelling task.
    *   Often a first step in extracting knowledge from text.
    *   Example: "Have you taken any courses at the [Politecnico di Milano]_(Institution)_ taught by [Mark Carman]_(Person)_?"
*   **Named Entity Recognition (NER) - Details (Slide 22):**
    *   **Named entity:** An object in the real world.
    *   **Most common tags:**
        *   `PER` (Person): e.g., "Marie Curie"
        *   `LOC` (Location): e.g., "Lake Michigan"
        *   `ORG` (Organization): e.g., "Stanford University"
        *   `GPE` (Geo-Political Entity): e.g., "Boulder, Colorado"
    *   Entities are often **multi-word phrases**.
    *   Term also extended to non-entities like **dates, times, prices**.
    *   **NER task:** Find spans in text that constitute proper names and tag their type.
*   **Why NER? (Slide 23):**
    *   **Sentiment analysis:** Identify sentiment towards a specific company/person.
    *   **Information extraction:** Extracting facts about entities.
    *   **Question answering:** Answering questions about an entity.
    *   **De-identification:** Removing references to individuals for privacy.
*   **NER Hardships:**
    1.  **Segmentation:** POS tagging assigns one tag per word; NER entities can be phrases.
    2.  **Type ambiguity:** The same word/phrase can have different entity types depending on context (e.g., "Paris Hilton" (Person) vs. "Paris Hilton" (Institution - a hotel)).
*   **Begin-Inside-Outside (BIO) Tagging (Slide 24):**
    *   Turns NER (phrase identification) into a sequence labeling problem (one label per token).
    *   Uses tags:
        *   `B-TYPE`: Token that **begins** a span of type TYPE (e.g., B-PER).
        *   `I-TYPE`: Token that is **inside** a span of type TYPE (e.g., I-PER).
        *   `O`: Token that is **outside** of any named entity span.
    *   Example: "[PER Jane Villanueva]" -> Jane (B-PER), Villanueva (I-PER).

### C. Entity Linkage (Slides 25-26)

*   **What is Entity Linkage (Entity Disambiguation/Normalization)? (Slide 26):**
    *   **Part 1 (NER):** Determining that a named-entity has been mentioned.
    *   **Part 2 (Linking):** Determining which **real-world entity** was referred to.
    *   Not as easy as it sounds due to ambiguity.
        *   "Paris" could refer to Paris, France; Paris, Texas; Paris Hilton.
        *   "Michael Jordan" (basketball player) vs. "Michael Jordan" (AI researcher at EMNLP).
*   **Linkage techniques make use of:**
    *   Relative importance/prominence of entities (e.g., Paris, France is more common).
    *   Context within text (other entities present, surrounding words).
*   **Ontology/Knowledge Base:**
    *   Generally **Wikipedia/DBPedia** is used as a target for linking.
    *   Many individuals/objects may not have a Wikipedia page, requiring custom ontologies (especially for domains like medicine).

### D. Relation Extraction (Slides 27-28)

*   **What is Relation Extraction? (Slide 28):**
    *   Once entity mentions have been linked to unique entities, **relationships between entities** can be mined.
    *   Used to populate a knowledge graph / knowledge base.
    *   Example: From "[Paris] is the capital of [France]", extract `Relation: capitalOf (Paris, France)`.
*   Handled as a problem of predicting **missing links** in a graph.
*   **Entity embeddings** can be leveraged:
    *   Translations in the embedding space can naturally encode relationships.
    *   (Ref: [https://arxiv.org/pdf/2002.00388.pdf](https://arxiv.org/pdf/2002.00388.pdf) for examples with knowledge graph embeddings).

### E. Parse Trees (Slides 29-32)

*   **Parse Trees (Syntax Parse Trees / Dependency Parse Trees) (Slide 30):**
    *   Result from applying a **formal grammar** to analyze a sentence.
    *   Formal grammars define rules for generating valid text (e.g., `S -> NP VP`, `VP -> V NP`). Often used for programming languages.
*   **Parsing:** Given text, reverse the process to determine which rules were applied and in what order, resulting in a **tree structure** for each sentence.
*   **Parse trees tell us:**
    *   How words in the sentence **relate to one another**.
    *   From which we can try to deduce **intended meaning (semantics)**.
*   Theoretically, ML isn't needed for parsing if a formal grammar exists. In practice, formal grammars are brittle, and natural language is ambiguous, so ML is used.
*   **What are Parse Trees useful for? (Slide 31):**
    *   **Understanding the meaning** of a sentence.
    *   Examples:
        *   "The store was out of food."
        *   "The chef who ran to the store was out of food."
    *   To populate a database or generate a consistent next sentence, we need to know **who did what**. In the second sentence, it was the *chef* who was out of food, not the store. This is found in the parse tree (dependency relations).
*   **Penn Treebank (Slide 32):**
    *   Famous dataset pairing sentences (one million words from Wall Street Journal) with their parse trees.
    *   Example: "“We would have to wait until we have collected on those assets” he said." and its corresponding tree structure.

### F. Co-reference Resolution (Slides 33-36)

*   **Co-reference Resolution (Slide 34):**
    *   Problem of determining **who or what is being referenced** by pronouns, definite noun phrases, etc., across (or sometimes within) sentences.
    *   Example: "John went to Bill's car dealership to check out an Acura Integra. **He** looked at **it** for half an hour."
        *   Who is **he**? -> John
        *   What is **it**? -> Bill's car dealership OR an Acura Integra (ambiguous without further context/world knowledge).
*   **Order of Pronouns and Referents (Slide 35):**
    *   Most times the pronoun comes **after** the referent (anaphora).
    *   Sometimes the pronoun comes **before** the referent (cataphora): "Before **he** bought it, John checked over the Integra..."
*   **Why resolve co-references?**
    *   To understand what is being said about entities.
    *   Needed for information extraction and chatbots.
*   **Types of Reference Phenomena (Slide 36):**
    *   **Pronouns:** "I saw no less than 6 Acura Integras today. **They** are the coolest cars." (They -> Acura Integras).
    *   **Non-pronominal anaphora (Definite Noun Phrases):** "I saw no less that 6 Acura Integra today. I want **one**." (one -> an Acura Integra).
    *   **Inferable anaphora (Bridging):** "I almost bought an Acura Integra today, but **the engine** seemed noisy." (the engine -> engine of the Acura).
    *   **Demonstratives (this, these, that, those):** Can refer to entities ("I like **this one** [Integra]"), or abstract concepts:
        *   Speech acts: "...Bob bought Sue an Integra... But **that** turned out to be a lie."
        *   Propositions: "...But **that** was false."
        *   Manner of description: "**That** struck me as a funny way..."
        *   Events: "**That** caused Sue to become rather poor."

### G. Taxonomies and Ontologies (Slides 37-40)

*   **What are Taxonomies and Ontologies? (Slide 38):**
    *   **Taxonomy:** A hierarchy of concepts (e.g., product types with *is-a* or *part-of* relationships).
    *   **Ontology:** A formal definition of concepts, abstract and language-independent.
*   **Most ontologies are composed of:**
    *   **Classes:** A set of objects / a type (e.g., `wine`).
    *   **Individuals:** An object instance (e.g., `champagne` is an instance of `wine`).
    *   **Attributes:** Properties (e.g., `price`) with primitive data types (e.g., `integer`) and restrictions (e.g., `>0`).
    *   **Relationships:** Characterization of relations among classes or individuals (e.g., `winery produces wine`).
    *   **Logical rules:** e.g., `hasParent(?x1,?x2) ^ hasBrother(?x2,?x3) → hasUncle(?x1,?x3)`.
*   **Ontologies as Graphs (Slide 39):**
    *   Relationships between concepts in an ontology/knowledge base form a graph.
    *   Can represent facts from sentences (e.g., "I have a car" -> Speaker `INSTANCE_OF` HumanBeing, HumanBeing `OWNS` Car).
*   **Knowledge Base Semantics (OWL) (Slide 40):**
    *   **OWL (Web Ontology Language):** Based on RDF (triple: subject-predicate-object) and Description Logic. Uses SPARQL for querying.
    *   **Open World Assumption (OWA):** Any statement not known to be true is **unknown**.
        *   Contrast with **Closed World Assumption (CWA)** in databases (SQL): any statement not known to be true is considered false (negation as failure).
    *   **Example:** KB contains "Giovanni is an architect" and "Giovanni is not a physicist".
        *   Query: "Is Giovanni an engineer?"
            *   OWA answer: **unknown**.
            *   CWA answer: **no** (proposition not in KB).
        *   Query: "Is Giovanni a physicist?"
            *   OWA answer: **no** (negated proposition found).
            *   CWA answer: **no** (proposition not in KB, also negated proposition found).

---

## VI. Conclusions (Slides 41-42)

*   The meaning of text depends on the **order of words**.
*   **Sequence classifiers** take word order into account when categorizing text (entire sequence to one label).
*   **Sequence labellers** label each word in the sequence (sequence to sequence of labels).
*   **Recurrent neural networks (RNNs, LSTMs)** are powerful models for learning from sequences.
*   **Typical NLP tasks involving sequence modeling include:**
    *   Part-of-speech tagging
    *   Named entity extraction and entity linkage
    *   Relation extraction
    *   Dependency parsing
    *   Co-reference resolution
    *   (Underlying many of these is the construction/use of ontologies/knowledge bases)

---
```
